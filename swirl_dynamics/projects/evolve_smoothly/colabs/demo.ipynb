{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nysrv9MI-WP7"
      },
      "outputs": [],
      "source": [
        "# !pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYh7q8S8-b-a"
      },
      "outputs": [],
      "source": [
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import orbax.checkpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "from swirl_dynamics.data import tfgrain_transforms as transforms\n",
        "from swirl_dynamics.lib.networks import encoders\n",
        "from swirl_dynamics.lib.solvers import ode\n",
        "from swirl_dynamics.projects.evolve_smoothly import ansatzes\n",
        "from swirl_dynamics.projects.evolve_smoothly import batch_decode\n",
        "from swirl_dynamics.projects.evolve_smoothly import data_pipelines\n",
        "from swirl_dynamics.projects.evolve_smoothly import encode_decode\n",
        "from swirl_dynamics.projects.evolve_smoothly import latent_dynamics\n",
        "from swirl_dynamics.templates import callbacks\n",
        "from swirl_dynamics.templates import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsJx7cYXJXhs"
      },
      "outputs": [],
      "source": [
        "tf.config.experimental.set_visible_devices([], \"GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "525SaoWa_Vt7"
      },
      "source": [
        "### Batch Decode Training\n",
        "\n",
        "This training involves fitting the same ansatz to a large number of snapshots. The resulting error provides evidence whether the selected ansatz is sufficiently expressive for the problem considered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZspPRRPFA7J_"
      },
      "source": [
        "We first set up the data pipeline using grain. This dataset contains a large number of snapshots with its batch dimension corresponding to grid points. In other words, a random sample represents all snapshots evaluated at these collocation points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRGb73BrraD8"
      },
      "outputs": [],
      "source": [
        "hdf5_file_path = \"/swirl_dynamics/hdf5/pde/1d/ks_trajectories.hdf5\"  #@param\n",
        "num_snapshots = 5000  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gRGLOAXEFIu"
      },
      "outputs": [],
      "source": [
        "train_dataloader = data_pipelines.create_batch_decode_pipeline(\n",
        "    hdf5_file_path = hdf5_file_path,\n",
        "    snapshot_field = \"train/u\",\n",
        "    grid_field = \"train/x\",\n",
        "    num_snapshots_to_train = num_snapshots,\n",
        "    transformations = [\n",
        "        # this rescales the grid from [0, L) to [-1, 1)\n",
        "        transforms.LinearRescale(\n",
        "            feature_name = \"x\", input_range = (0, 64), output_range = (-1, 1))\n",
        "    ],\n",
        "    seed = 42,\n",
        "    batch_size = 32,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nYIYGl5E0Km"
      },
      "source": [
        "Next we instantiate the model, which takes an ansatz model (wrapped to provide easy access to things like parameter shapes and structures) and the number of snapshots in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2ciuavX0RFq"
      },
      "outputs": [],
      "source": [
        "ansatz = ansatzes.NonLinearFourier(\n",
        "    model=ansatzes.nonlinear_fourier.NonLinearFourier(\n",
        "        features=(8, 8),\n",
        "        num_freqs=3,\n",
        "        act_fn=jnp.sin,\n",
        "        zero_freq=False,\n",
        "        dyadic=False\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HWUwwhpEli3"
      },
      "outputs": [],
      "source": [
        "model = batch_decode.BatchDecode(\n",
        "  ansatz=ansatz, num_snapshots = num_snapshots,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7gnVX4lu5wW"
      },
      "source": [
        "Thirdly, we instantiate the trainer, which takes the model, a random seed and an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDd_mN1mO5a4"
      },
      "outputs": [],
      "source": [
        "trainer = batch_decode.BatchDecodeTrainer(\n",
        "    model=model, rng=jax.random.PRNGKey(42), optimizer=optax.adam(1e-3)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpaZIyiKvF7n"
      },
      "source": [
        "We can now run training and monitor progress. The fact that the training loss is fairly low at the end is a promising sign - the ansatz we adopted has the expressive power to represent a wide range of snapshots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoK1IQH5uO-e"
      },
      "outputs": [],
      "source": [
        "workdir = \"batch_decode/\"  #@param\n",
        "num_train_steps = 20000  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR8GiIMOQ3WY"
      },
      "outputs": [],
      "source": [
        "train.run(\n",
        "  train_dataloader=train_dataloader,\n",
        "  trainer=trainer,\n",
        "  workdir=workdir,\n",
        "  total_train_steps=num_train_steps,\n",
        "  metric_aggregation_steps=50,\n",
        "  callbacks=[\n",
        "    callbacks.TqdmProgressBar(\n",
        "        total_train_steps=num_train_steps,\n",
        "        train_monitors=[\"train_loss\", \"train_loss_std\"]\n",
        "    ),\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69ba-Ocdei9l"
      },
      "source": [
        "### Encode Decode Training\n",
        "\n",
        "This stage involves using an encoder network to output the weights of an ansatz that parametrizes snapshots. By incorporating the consistency loss, we obtain smooth weight trajectories which prove to be beneficial for training dynamics later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJtXnE2bejcj"
      },
      "outputs": [],
      "source": [
        "transforms = [\n",
        "    # this rescales the grid from [0, L) to [-1, 1)\n",
        "    transforms.LinearRescale(\n",
        "        feature_name=\"x\", input_range=(0, 64), output_range=(-1, 1))\n",
        "]\n",
        "\n",
        "train_dataloader = data_pipelines.create_encode_decode_pipeline(\n",
        "    hdf5_file_path=hdf5_file_path,\n",
        "    snapshot_field=\"train/u\",\n",
        "    grid_field=\"train/x\",\n",
        "    transformations=transforms,\n",
        "    seed=42,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "eval_dataloader = data_pipelines.create_encode_decode_pipeline(\n",
        "    hdf5_file_path=hdf5_file_path,\n",
        "    snapshot_field=\"eval/u\",\n",
        "    grid_field=\"eval/x\",\n",
        "    transformations=transforms,\n",
        "    seed=42,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpBCGOO1eum5"
      },
      "outputs": [],
      "source": [
        "ansatz = ansatzes.NonLinearFourier(\n",
        "    model=ansatzes.nonlinear_fourier.NonLinearFourier(\n",
        "        features=(8, 8),\n",
        "        num_freqs=3,\n",
        "        act_fn=jnp.sin,\n",
        "        zero_freq=False,\n",
        "        dyadic=False\n",
        "    )\n",
        ")\n",
        "encoder = encoders.EncoderResNet(\n",
        "    filters=4,\n",
        "    dim_out=ansatz.num_params,\n",
        "    num_levels=4,\n",
        "    num_resnet_blocks=2,\n",
        "    act_fn=jnp.sin\n",
        ")\n",
        "model = encode_decode.EncodeDecode(\n",
        "    ansatz=ansatz,\n",
        "    encoder=encoder,\n",
        "    snapshot_dims=(1, 512, 1),\n",
        "    consistency_weight=10.,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK_4yBKVt5Lu"
      },
      "source": [
        "Define an exponentially decay learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsEc1_cSt30Z"
      },
      "outputs": [],
      "source": [
        "lr = optax.warmup_cosine_decay_schedule(\n",
        "    init_value = 0.0,\n",
        "    peak_value = 1e-4,\n",
        "    warmup_steps = 1000,\n",
        "    decay_steps = 99000,\n",
        "    end_value = 1e-6,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP3fbtrDt_W3"
      },
      "source": [
        "For the optimizer we use adam with norm-based gradient clipping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8AdpAg4t_Mc"
      },
      "outputs": [],
      "source": [
        "optimizer = optax.chain(\n",
        "    optax.clip_by_global_norm(max_norm=1.),\n",
        "    optax.adam(lr)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-jaLDANmrjW"
      },
      "outputs": [],
      "source": [
        "trainer = encode_decode.EncodeDecodeTrainer(\n",
        "    model=model, rng=jax.random.PRNGKey(1), optimizer=optimizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFUUSP4mw0v9"
      },
      "source": [
        "Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnth-O2P5Ssn"
      },
      "outputs": [],
      "source": [
        "workdir = \"/tmp/encode_decode/\"  #@param\n",
        "num_train_steps = 100000  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5LWu9klKtvJ"
      },
      "outputs": [],
      "source": [
        "train.run(\n",
        "  train_dataloader=train_dataloader,\n",
        "  trainer=trainer,\n",
        "  workdir=workdir,\n",
        "  total_train_steps=num_train_steps,\n",
        "  metric_aggregation_steps=50,\n",
        "  eval_dataloader=eval_dataloader,\n",
        "  eval_every_steps=2000,\n",
        "  num_batches_per_eval=10,\n",
        "  callbacks=[\n",
        "    callbacks.TrainStateCheckpoint(\n",
        "        base_dir=workdir,  # NOTE: this must be a full path\n",
        "        options=orbax.checkpoint.CheckpointManagerOptions(\n",
        "            save_interval_steps=1000,\n",
        "            max_to_keep=5,\n",
        "        )\n",
        "    ),\n",
        "    callbacks.TqdmProgressBar(\n",
        "        total_train_steps=num_train_steps,\n",
        "        train_monitors=(\"train_loss\",),\n",
        "        eval_monitors=(\"eval_reconstruction_rel_l2\",)),\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1XPsF69KSRO"
      },
      "source": [
        "Check inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uSv1-IEKGsz"
      },
      "outputs": [],
      "source": [
        "encode_fn = encode_decode.EncodeDecodeTrainer.build_inference_fn(\n",
        "    trainer.train_state, encoder\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD01bq9YLIwz"
      },
      "outputs": [],
      "source": [
        "eval_batch = next(iter(eval_dataloader))\n",
        "encoding = encode_fn(eval_batch[\"u\"])\n",
        "reconstruction = jax.vmap(ansatz.batch_evaluate, in_axes=(0, 0))(encoding, eval_batch[\"x\"])\n",
        "print(reconstruction.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky9zdtX_Mq9d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "plt.plot(\n",
        "    eval_batch[\"x\"][0, :, 0], reconstruction[0, :, 0], label=\"reconstruction\"\n",
        ")\n",
        "plt.plot(\n",
        "    eval_batch[\"x\"][0, :, 0], eval_batch[\"u\"][0, :, 0], label=\"true\"\n",
        ")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRGPFCvuf8hH"
      },
      "source": [
        "### Latent Dynamics Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6aRSTuYNpiF"
      },
      "source": [
        "After encoder training, we train a latent dynamical model on the resulting latent trajectories (frozen encoder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQm3KTxMf8Wr"
      },
      "outputs": [],
      "source": [
        "transforms = [\n",
        "    # this rescales the grid from [0, L) to [-1, 1)\n",
        "    transforms.LinearRescale(\n",
        "        feature_name=\"x\", input_range=(0, 64), output_range=(-1, 1))\n",
        "]\n",
        "\n",
        "\n",
        "train_dataloader = data_pipelines.create_latent_dynamics_pipeline(\n",
        "    hdf5_file_path=hdf5_file_path,\n",
        "    snapshot_field=\"train/u\",\n",
        "    tspan_field=\"train/t\",\n",
        "    grid_field=\"train/x\",\n",
        "    num_time_steps=2,\n",
        "    transformations=transforms,\n",
        "    seed=42,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "eval_dataloader = data_pipelines.create_latent_dynamics_pipeline(\n",
        "    hdf5_file_path=hdf5_file_path,\n",
        "    snapshot_field=\"eval/u\",\n",
        "    tspan_field=\"eval/t\",\n",
        "    grid_field=\"eval/x\",\n",
        "    num_time_steps=2,\n",
        "    transformations=transforms,\n",
        "    seed=42,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaEVyYc6N9d7"
      },
      "outputs": [],
      "source": [
        "latent_dynamics_model = latent_dynamics.create_hyperunet_dynamics_model(\n",
        "    ansatz=ansatz,\n",
        "    embed_dims=(4, 256, 1024),\n",
        "    act_fn=nn.swish,\n",
        "    use_layernorm=True,\n",
        ")\n",
        "integrator = ode.RungeKutta4()\n",
        "model = latent_dynamics.LatentDynamics(\n",
        "    encoder=encode_fn,\n",
        "    ansatz=ansatz,\n",
        "    latent_dynamics_model=latent_dynamics_model,\n",
        "    integrator=integrator,\n",
        "    reconstruction_weight=0.0,\n",
        "    latent_weight=1.0,\n",
        "    consistency_weight=1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKYaaXn1N8_0"
      },
      "outputs": [],
      "source": [
        "optimizer = optax.chain(\n",
        "    optax.clip_by_global_norm(max_norm=1.),\n",
        "    optax.adam(\n",
        "        optax.warmup_cosine_decay_schedule(\n",
        "            init_value = 0.0,\n",
        "            peak_value = 1e-4,\n",
        "            warmup_steps = 1000,\n",
        "            decay_steps = 99000,\n",
        "            end_value = 1e-6,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "trainer = latent_dynamics.LatentDynamicsTrainer(\n",
        "    model=model, rng=jax.random.PRNGKey(1), optimizer=optimizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jRmUzgnRZrj"
      },
      "outputs": [],
      "source": [
        "workdir = \"/tmp/latent_dynamics/\"  #@param\n",
        "num_train_steps = 100000  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-UyaaaqRhiw"
      },
      "outputs": [],
      "source": [
        "train.run(\n",
        "  train_dataloader=train_dataloader,\n",
        "  trainer=trainer,\n",
        "  workdir=workdir,\n",
        "  total_train_steps=num_train_steps,\n",
        "  metric_aggregation_steps=50,\n",
        "  eval_dataloader=eval_dataloader,\n",
        "  eval_every_steps=2500,\n",
        "  num_batches_per_eval=10,\n",
        "  callbacks=[\n",
        "    callbacks.TrainStateCheckpoint(\n",
        "        base_dir=workdir,  # NOTE: this must be a full path\n",
        "        options=orbax.checkpoint.CheckpointManagerOptions(\n",
        "            save_interval_steps=5000,\n",
        "            max_to_keep=5,\n",
        "        )\n",
        "    ),\n",
        "    callbacks.TqdmProgressBar(\n",
        "        total_train_steps=num_train_steps,\n",
        "        train_monitors=(\"train_loss\",),\n",
        "        eval_monitors=(\"eval_latent_rel_l2\",)),\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMRRwsBLVFKa"
      },
      "source": [
        "Here we check inference by predicting 2 steps forward in time using the trained latent dynamical model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6qfiuPpR5Iw"
      },
      "outputs": [],
      "source": [
        "dm = latent_dynamics.LatentDynamicsTrainer.build_inference_fn(\n",
        "    trainer.train_state,\n",
        "    encoder=encode_fn,\n",
        "    ansatz=ansatz,\n",
        "    latent_dynamics_model=latent_dynamics_model,\n",
        "    integrator=integrator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKb4jkA-VVG8"
      },
      "outputs": [],
      "source": [
        "eval_batch = next(iter(eval_dataloader))\n",
        "evolution = dm(\n",
        "    u0=eval_batch[\"u\"][:, 0], tspan=eval_batch[\"t\"], grid=eval_batch[\"x\"]\n",
        ")\n",
        "print(evolution.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORbNCj4lVrtY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "plt.plot(\n",
        "    eval_batch[\"x\"][0, :, 0], evolution[0, -1, :, 0], label=\"predicted\"\n",
        ")\n",
        "plt.plot(\n",
        "    eval_batch[\"x\"][0, :, 0], eval_batch[\"u\"][0, -1, :, 0], label=\"true\"\n",
        ")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbYTF676YfDk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//third_party/py/swirl_dynamics/projects/evolve_smoothly:colab_binary",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1aCRktPvwidGDpK5AQil6JW0tCbqfampK",
          "timestamp": 1686871795292
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
