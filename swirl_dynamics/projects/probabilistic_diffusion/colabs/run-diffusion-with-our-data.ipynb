{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3FaJ8OvwB2F"
      },
      "source": [
        "This notebook includes the diffusion model training on ECMWF forecasts data. It also includes the inference on a single batch to allow some visualization of the generated samples. However, the complete inference on the whole test dataset will be run in the *evaluation* notebook.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP6GQNwnCrwz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd swirl-dynamics\n",
        "\n",
        "#!pip install clu\n",
        "#!pip install grain\n",
        "#!pip install xarray-tensorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lo5B352ypP9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714141968269,
          "user_tz": -120,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "824f1d4a-b2ae-44ce-9842-e22ef8884191"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/swirl-dynamics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd swirl_dynamics/projects/probabilistic_diffusion/colabs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVjOkK-JzeAt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714141985912,
          "user_tz": -120,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d50888fd-1537-4407-a29a-27eb73f6767a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/swirl-dynamics/swirl_dynamics/projects/probabilistic_diffusion/colabs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZDKhSAGaCrk2",
        "tags": [],
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714141986848,
          "user_tz": -120,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import functools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import optax\n",
        "import orbax.checkpoint as ocp\n",
        "import tensorflow as tf\n",
        "from clu import metric_writers\n",
        "\n",
        "from swirl_dynamics import templates\n",
        "from swirl_dynamics.lib import diffusion as dfn_lib\n",
        "from swirl_dynamics.lib import solvers as solver_lib\n",
        "from swirl_dynamics.projects import probabilistic_diffusion as dfn\n",
        "\n",
        "from read_data import get_cond_ecmwf_dataset, get_mean_std_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4xz1w9GkFE"
      },
      "source": [
        "## Conditional diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElgwVoIPGxRq"
      },
      "source": [
        "In the above example, we trained an *unconditional* diffusion model and applied conditioning at inference time. This is not always easy to do, depending on how the conditioning input relates to the samples.\n",
        "\n",
        "Alternatively, we can directly *train a conditional model*, where the conditional signal is provided at training time as an additional input to the denoising neural network, which may then use it to compute the denoised target.\n",
        "\n",
        "Below we show an example of how to accomplish this. We again generate samples of handwritten digits, using the MNIST dataset for training. We will condition the generation on the `x[11:18, 11:18]` patch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-O2msbGzEx"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba3Wn2YvG1oC"
      },
      "source": [
        "Besides the sample in `x`, the dataset for training conditional models require a `cond` key which contains the condition signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4IpRYEJtGD-Q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142057683,
          "user_tz": -120,
          "elapsed": 359,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "DATA_STD = 0.31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slazLkO-wB2Y",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142170260,
          "user_tz": -120,
          "elapsed": 1103,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "24e0d3d1-2897-44e0-fd4d-7452ae7f500e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 28, 28)\n",
            "(4, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "for array in get_cond_ecmwf_dataset(split=\"test\", batch_size=4):\n",
        "    print(array['x'].shape)\n",
        "    print(array['cond'][\"channel:low_res\"].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yOBMiJtG7r3",
        "tags": []
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNUY5kQG9xd"
      },
      "source": [
        "The architecture is similar to the unconditional case. We provide additional args that specify how to resize the conditioning signal (in order to be compatible with the noisy sample for channel-wise concatenation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M5F8kNMAGiTR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142306881,
          "user_tz": -120,
          "elapsed": 404,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "cond_denoiser_model = dfn_lib.PreconditionedDenoiser(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128),\n",
        "    downsample_ratio=(2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=True,\n",
        "    num_heads=8,\n",
        "    sigma_data=DATA_STD,\n",
        "    cond_resize_method=\"cubic\",\n",
        "    cond_embed_dim=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19oJrFsjHCIZ",
        "tags": []
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0JP9yAHEem"
      },
      "source": [
        "The `DenoisingModel` is again similar to the unconditional case. We additionally provide the shape information of the `cond` input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xJFKb060GiRH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142321640,
          "user_tz": -120,
          "elapsed": 289,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = dfn_lib.Diffusion.create_variance_exploding(\n",
        "    sigma=dfn_lib.tangent_noise_schedule(),\n",
        "    data_std=DATA_STD,\n",
        ")\n",
        "\n",
        "cond_model = dfn.DenoisingModel(\n",
        "    input_shape=(28, 28, 1),\n",
        "    # `cond_shape` must agree with the expected structure and shape\n",
        "    # (without the batch dimension) of the `cond` input.\n",
        "    cond_shape={\"channel:low_res\": (28, 28, 1)},\n",
        "    denoiser=cond_denoiser_model,\n",
        "    noise_sampling=dfn_lib.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=dfn_lib.edm_weighting(data_std=DATA_STD),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Bktr9gHHjz"
      },
      "source": [
        "The rest mostly repeats the unconditional training example, replacing the datasets and model with their conditional counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oyEsCCSbGiPC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142332636,
          "user_tz": -120,
          "elapsed": 299,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $cond_workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ekXD8PprGiM8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1714142710822,
          "user_tz": -120,
          "elapsed": 523,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "num_train_steps = 100000  #@param\n",
        "cond_workdir = \"gs://wfp-ml4aa-data/chkpts/gcp/cond_diffusion_ecmwf_fix_datastd\"  #@param\n",
        "train_batch_size = 128  #@param\n",
        "eval_batch_size = 128  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DDpmV-zGiKW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cond_trainer = dfn.DenoisingTrainer(\n",
        "    model=cond_model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    ema_decay=ema_decay,\n",
        ")\n",
        "\n",
        "templates.run_train(\n",
        "    train_dataloader=get_cond_ecmwf_dataset(\n",
        "        split=\"train\", batch_size=train_batch_size\n",
        "    ),\n",
        "    trainer=cond_trainer,\n",
        "    workdir=cond_workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_writer=metric_writers.create_default_writer(\n",
        "        cond_workdir, asynchronous=False\n",
        "    ),\n",
        "    metric_aggregation_steps=100,\n",
        "    eval_dataloader=get_cond_ecmwf_dataset(\n",
        "        split=\"train\", batch_size=eval_batch_size\n",
        "    ),\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        templates.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        templates.TrainStateCheckpoint(\n",
        "            base_dir=cond_workdir,\n",
        "            options=ocp.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojUo2JDEHPCN"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS0m_f0CHR5i"
      },
      "source": [
        "To perform inference/sampling, let's load back the trained conditional model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RHlke6pGiHx"
      },
      "outputs": [],
      "source": [
        "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
        "    f\"{cond_workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "cond_denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=cond_denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3crKP7hqHV7I"
      },
      "source": [
        "The conditional sampler again follows the previous example, with the only exception being that the conditional model replaces the unconditional one.\n",
        "\n",
        "Below we do not apply any guidance, but one can be easily added in the same way as in the unconditional example above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnaFzOjOHOu4"
      },
      "outputs": [],
      "source": [
        "cond_sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=cond_denoise_fn,\n",
        "    guidance_transforms=(),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lYF1OUEHZFM"
      },
      "source": [
        "We again JIT the generate function for the sake of faster repeated sampling calls. Here we employ `functools.partial` to specify `num_samples=5`, making it easier to vectorize across the batch dimension with `jax.vmap`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_rLzdgHOsm"
      },
      "outputs": [],
      "source": [
        "num_samples_per_cond = 5\n",
        "\n",
        "generate = jax.jit(\n",
        "    functools.partial(cond_sampler.generate, num_samples_per_cond)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_9TfCMSHd3P"
      },
      "source": [
        "Loading a test batch of conditions with 4 elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tODWrPBfHOqN"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "test_ds = next(iter(get_cond_ecmwf_dataset(split=\"test\", batch_size=batch_size)))\n",
        "test_batch_cond = test_ds[\"cond\"]\n",
        "test_batch_gt = test_ds[\"x\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Tpjd0fvBwB2i"
      },
      "outputs": [],
      "source": [
        "mean_chirps, var_chirps, mean_ecmwf, var_ecmwf = get_mean_std_data(split=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJXzAtzHhli"
      },
      "source": [
        "The vectorized generate function is applied to the loaded batch. The vectorization occurs for the leading dimensions of both the random seed and the condition (for those unfamiliarized with vectorized operations in jax, think of a more efficient `for` loop that iterates over the random seeds and batch conditions zipped together)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29oPpGuWHhYP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cond_samples = jax.vmap(generate, in_axes=(0, 0, None))(\n",
        "    jax.random.split(jax.random.PRNGKey(8888), batch_size),\n",
        "    test_batch_cond,\n",
        "    None,  # Guidance inputs = None since no guidance transforms involved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH9CozY8Hkgv"
      },
      "source": [
        "The result `cond_samples` has shape `(batch_size, num_samples_per_cond, *input_shape)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSQHV5FmHOoK"
      },
      "outputs": [],
      "source": [
        "print(cond_samples.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br6clK2cHow9"
      },
      "source": [
        "Visualize generated examples alongside their low-res conditioning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7c5wXDcHOkP"
      },
      "outputs": [],
      "source": [
        "for i in range(batch_size):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(4, 4))\n",
        "    im = ax[0].imshow(\n",
        "        test_batch_cond[\"channel:low_res\"][i, :, :, 0] * (var_ecmwf + 1e-4) + mean_ecmwf,\n",
        "        cmap=\"viridis\",\n",
        "    )\n",
        "    ax[0].axis(\"off\")\n",
        "    ax[0].set_title(f\"Low-res condition: #{i + 1}\")\n",
        "\n",
        "    fig.colorbar(im, ax=ax[0])\n",
        "\n",
        "    im = ax[1].imshow(\n",
        "        test_batch_gt[i, :, :, 0]  * (var_chirps + 1e-4) + mean_chirps,\n",
        "        cmap=\"viridis\",\n",
        "    )\n",
        "    ax[1].axis(\"off\")\n",
        "    ax[1].set_title(f\"Hi-res GT: #{i + 1}\")\n",
        "\n",
        "    fig.colorbar(im, ax=ax[1])\n",
        "\n",
        "    min_hi_res = np.min(test_batch_gt[i, :, :, 0]  * (var_chirps + 1e-4) + mean_chirps)\n",
        "    max_hi_res = np.max(test_batch_gt[i, :, :, 0]  * (var_chirps + 1e-4) + mean_chirps)\n",
        "\n",
        "    # Plot generated samples.\n",
        "    fig, ax = plt.subplots(\n",
        "        1, num_samples_per_cond, figsize=(num_samples_per_cond * 2, 2)\n",
        "    )\n",
        "    for j in range(num_samples_per_cond):\n",
        "        if num_samples_per_cond == 1:\n",
        "            im = ax.imshow(\n",
        "                cond_samples[i, j, :, :, 0] * (var_chirps + 1e-4) + mean_chirps,\n",
        "                cmap=\"viridis\",\n",
        "                vmin=min_hi_res,\n",
        "                vmax=max_hi_res,\n",
        "            )\n",
        "            ax.set_title(f\"conditional sample: #{j + 1}\")\n",
        "            ax.axis(\"off\")\n",
        "        else:\n",
        "            im = ax[j].imshow(\n",
        "                cond_samples[i, j, :, :, 0] * (var_chirps + 1e-4) + mean_chirps,\n",
        "                cmap=\"viridis\",\n",
        "                vmin=min_hi_res,\n",
        "                vmax=max_hi_res,\n",
        "            )\n",
        "            ax[j].set_title(f\"conditional sample: #{j + 1}\")\n",
        "            ax[j].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Ys0ltBwB2k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "provenance": [
        {
          "file_id": "1eA8hF0r-tUgIX-miyPgPkzH80WjzCarp",
          "timestamp": 1707268348992
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "swirl",
      "language": "python",
      "name": "conda-env-swirl-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}