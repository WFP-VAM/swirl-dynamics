{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuoBVM5f-FoH"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuIc-c6La1kb"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/google-research/swirl-dynamics.git@main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irygY1V9-RWK"
      },
      "source": [
        "## Example - training an unconditional diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9RFLAtk-CQN"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttM1kQvfrDB5"
      },
      "source": [
        "First we need a dataset containing samples whose distribution is to be modeled by the diffusion model. This is application dependent so below we use a pair of dummy train and evaluation dataloaders, which should be replaced with realistic ones for your specific use case.\n",
        "\n",
        "Our code setup accepts any Python Iterable objects to be used as dataloaders. The expectation is that they should continuously yield a dictionary with a field named `x` whose corresponding value is a numpy array with shape `(batch, *spatial_dims, channels)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKweWVyr-BAi"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-jPAOmnrG0Q"
      },
      "outputs": [],
      "source": [
        "# A batch with 8 2D samples (with spatial dim of 64x64 and 1 channel)\n",
        "fake_batch = {\"x\": np.ones((8, 64, 64, 1))}\n",
        "\n",
        "train_dataloader = eval_dataloader = itertools.repeat(fake_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbDmC9V--f3g"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsIAbw_t8_fh"
      },
      "source": [
        "Next let's define the U-Net backbone. The \"Preconditioning\" is merely to ensure that the inputs and outputs of the network are roughly standardized (for more details, see Appendix B.6. in [this paper](https://arxiv.org/abs/2206.00364))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoE_rulD-4BL"
      },
      "outputs": [],
      "source": [
        "from swirl_dynamics.lib.diffusion import unets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrUK52vP8kbc"
      },
      "outputs": [],
      "source": [
        "denoiser_model = unets.PreconditionedDenoiser(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128, 256),\n",
        "    downsample_ratio=(2, 2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=False,\n",
        "    num_heads=8,\n",
        "    sigma_data=0.25,  # standard deviation of the entire dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFkEPqag-iPv"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_tAv31f-0Rp"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "from orbax import checkpoint\n",
        "\n",
        "from swirl_dynamics.lib.diffusion import diffusion\n",
        "from swirl_dynamics.projects.probabilistic_diffusion import unconditional\n",
        "from swirl_dynamics.templates import callbacks\n",
        "from swirl_dynamics.templates import train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZV1dxjVAOVd"
      },
      "source": [
        "For diffusion model training, the above-defined U-Net backbone serves as a denoiser, which takes as input a batch of (isotropic Gaussian noise) corrupted samples and outputs its best guess for what the uncorrupted image would be.\n",
        "\n",
        "Besides the backbone architecture, we also need to specify how to sample the noise levels (i.e. standard deviations) used to corrupt the samples and the weighting for each noise level in the loss function (for other options and configurations, see [`swirl_dynamics.lib.diffusion.diffusion`](https://github.com/google-research/swirl-dynamics/blob/main/swirl_dynamics/lib/diffusion/diffusion.py)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiPBO4GJAN-Z"
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = diffusion.Diffusion.create_variance_exploding(\n",
        "    sigma=diffusion.tangent_noise_schedule(),\n",
        "    data_std=1.0,\n",
        ")\n",
        "model = unconditional.DenoisingModel(\n",
        "    input_shape=(64, 64, 1),  # this must agree with the expected sample shape (without the batch dimension)\n",
        "    denoiser=denoiser_model,\n",
        "    noise_sampling=diffusion.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=diffusion.edm_weighting(data_std=1.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaALfKOEBeTN"
      },
      "source": [
        "We are now ready to define the learning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMHTJDRpx23L"
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCA4SfBC8uaa"
      },
      "outputs": [],
      "source": [
        "num_train_steps = 10000  #@param\n",
        "workdir = \"/tmp/diffusion_demo\"  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_fGNK8AzcmA"
      },
      "source": [
        "To start training, we first need to initialize the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubgy3z7KzhuS"
      },
      "outputs": [],
      "source": [
        "# NOTE: use `unconditional.DistributedDenoisingTrainer` for multi-device\n",
        "# training with data parallelism\n",
        "trainer = unconditional.DenoisingTrainer(\n",
        "    model=model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    # We keep track of an exponential moving average of the model parameters\n",
        "    # over training steps. This alleviates the \"color-shift\" problems known to\n",
        "    # exist in the diffusion models.\n",
        "    ema_decay=ema_decay,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4YeJAhzwJw"
      },
      "source": [
        "Now we are ready to kick start training. A couple of \"callbacks\" are passed to assist with monitoring and checkpointing.\n",
        "\n",
        "The first step will be a little slow as Jax needs to JIT compile the step function (the same goes for the first step where evaluation is performed). Fortunately, steps after that should continue much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKKYq7WpzWkF"
      },
      "outputs": [],
      "source": [
        "train.run(\n",
        "    train_dataloader=train_dataloader,\n",
        "    trainer=trainer,\n",
        "    workdir=workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_aggregation_steps=20,\n",
        "    eval_dataloader=eval_dataloader,\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        # This callback displays the training progress in a tqdm bar\n",
        "        callbacks.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        # This callback saves model checkpoint periodically\n",
        "        callbacks.TrainStateCheckpoint(\n",
        "            base_dir=workdir,\n",
        "            options=checkpoint.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGrA3BC-O9Du"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrbCgv_P6D0n"
      },
      "source": [
        "#### Unconditional generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AURUIg5RT4m"
      },
      "source": [
        "The trained denoiser may be used to generate unconditional samples.\n",
        "\n",
        "First, let's try to restore the model from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVWUL7tSO81E"
      },
      "outputs": [],
      "source": [
        "# Restore train state from checkpoint. By default, the move recently saved\n",
        "# checkpoint is restored. Alternatively, one can directly use\n",
        "# `trainer.train_state` if continuing from the training section above.\n",
        "trained_state = unconditional.TrainState.restore_from_orbax_ckpt(\n",
        "    f\"{workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "denoise_fn = unconditional.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAe4bnTRYir"
      },
      "source": [
        "Diffusion samples are generated by plugging the trained denoising function in a stochastic differential equation (parametrized by the diffusion scheme) and solving it backwards in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpjRCvSaRWNv"
      },
      "outputs": [],
      "source": [
        "from swirl_dynamics.lib.diffusion import samplers\n",
        "from swirl_dynamics.lib.solvers import sde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVrmsxFNRbE4"
      },
      "outputs": [],
      "source": [
        "sampler = samplers.SdeSampler(\n",
        "    input_shape=(64, 64, 1),\n",
        "    integrator=sde.EulerMaruyama(),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMSyltl75wbE"
      },
      "outputs": [],
      "source": [
        "# Optional: JIT compile the generate function so that it runs faster if\n",
        "# repeatedly called.\n",
        "generate = jax.jit(sampler.generate, static_argnums=(2,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmSX8FSTW0ey"
      },
      "outputs": [],
      "source": [
        "# Time steps for the SDE solver\n",
        "tspan = samplers.exponential_noise_decay(\n",
        "    scheme=diffusion_scheme, num_steps=256, end_sigma=1e-3\n",
        ")\n",
        "samples, aux = generate(\n",
        "    rng=jax.random.PRNGKey(88), tspan=tspan, num_samples=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a_U_bNj-v83"
      },
      "source": [
        "In the output, `samples` is the generated samples and `aux` is the auxiliary output from the generation process. It contains the full trajectory of the SDE, which may be probed to better understand the generation behaviors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zp6JIEy-jof"
      },
      "outputs": [],
      "source": [
        "print(samples.shape)\n",
        "print(aux[\"trajectories\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbwCG7Nl54-8"
      },
      "source": [
        "Visualize the generated samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxwfwrHT54hB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeZUbr-c6oJq"
      },
      "outputs": [],
      "source": [
        "# Plot generated samples\n",
        "vmin, vmax = -3, 3\n",
        "\n",
        "fig, ax = plt.subplots(1, 4, figsize=(10, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(samples[i, :, :, 0], vmin=vmin, vmax=vmax)\n",
        "  fig.colorbar(im, ax=ax[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P8fl5EyAAgo"
      },
      "outputs": [],
      "source": [
        "# Plot SDE trajectory\n",
        "steps = 8\n",
        "sample_id = 0\n",
        "vmin, vmax = -3, 3\n",
        "\n",
        "fig, ax = plt.subplots(1, steps, figsize=(steps * 2.5, 2))\n",
        "for i in range(steps):\n",
        "  step_idx = i * (aux[\"trajectories\"].shape[0] // steps)\n",
        "  im = ax[i].imshow(\n",
        "      aux[\"trajectories\"][step_idx, sample_id, :, :, 0], vmin=vmin, vmax=vmax\n",
        "  )\n",
        "  ax[i].set_title(f\"diffusion time {tspan[step_idx]: .3f}\")\n",
        "  fig.colorbar(im, ax=ax[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWtflAEJ1ktz"
      },
      "source": [
        "#### A-posteriori guided generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWEr24aP728v"
      },
      "source": [
        "We may post-process a trained denoising function to perform \"guided\" generation. Below we provide an example for a super-resolution task: generating high-resolution images given a low-resolution one.\n",
        "\n",
        "To achieve this, we provide the low-resolution image as the guide input and post-process the denoiser to favor generating samples which, when downsampled, give values close to these guide input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVqIAcFM1jlY"
      },
      "outputs": [],
      "source": [
        "from swirl_dynamics.lib.diffusion import guidance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSptDBh31x3f"
      },
      "outputs": [],
      "source": [
        "guidance_fn = guidance.InfillFromSlices(\n",
        "    # This specifies location of the guide input using python slices.\n",
        "    # Here it implies that the guide input corresponds to pixels at 0, 8, ...\n",
        "    slices=(slice(None), slice(None, None, 8), slice(None, None, 8)),\n",
        "\n",
        "    # This is a parameter that controls how \"hard\" the denoiser pushes for\n",
        "    # the conditioning to be satisfied. At higher values, the conditioning is\n",
        "    # better satisfied in exchange for sample diversity.\n",
        "    guide_strength=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWJ0QMR_6yuD"
      },
      "outputs": [],
      "source": [
        "guided_sampler = samplers.SdeSampler(\n",
        "    input_shape=(64, 64, 1),\n",
        "    integrator=sde.EulerMaruyama(),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        "    guidance_fn=guidance_fn,\n",
        ")\n",
        "\n",
        "guided_generate = jax.jit(guided_sampler.generate, static_argnums=(2,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dLGoCMI7pXH"
      },
      "outputs": [],
      "source": [
        "guided_samples, _ = guided_generate(\n",
        "    rng=jax.random.PRNGKey(66),\n",
        "    tspan=samplers.exponential_noise_decay(\n",
        "        scheme=diffusion_scheme, num_steps=128, end_sigma=1e-3\n",
        "    ),\n",
        "    num_samples=4,\n",
        "    # The shape of the guidance input must be compatible with\n",
        "    # `sample[guidance_fn.slices]`\n",
        "    guidance_input=jnp.ones((1, 8, 8, 1)),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGwdwD79DF-D"
      },
      "source": [
        "Visualize guided samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mBAWlfiCgpw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGEGxeEjDNl1"
      },
      "outputs": [],
      "source": [
        "vmin, vmax = -3, 3\n",
        "\n",
        "fig, ax = plt.subplots(1, 4, figsize=(10, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(guided_samples[i, :, :, 0], vmin=vmin, vmax=vmax)\n",
        "  fig.colorbar(im, ax=ax[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-0VGYIFDovy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1zuI1jxu2lAxRCnuV9LvdINdbjSbHHHnR",
          "timestamp": 1695423423432
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
